{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_IRIS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/drive/1EwlmzTX7Zy89AEUogb-2hqfOPJbhPzEX)"
      ]
    },
    {
      "metadata": {
        "id": "RL13I-8b7vfX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "import numpy\n",
        "import pandas as pd\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# Defining column names for datasets\n",
        "COLUMN_NAMES = [\n",
        "        'SepalLength', \n",
        "        'SepalWidth',\n",
        "        'PetalLength', \n",
        "        'PetalWidth', \n",
        "        'Species'\n",
        "        ]\n",
        "\n",
        "# Import training dataset\n",
        "training_dataset = pd.read_csv('iris_training.csv', names=COLUMN_NAMES, header=0)\n",
        "train_x = training_dataset.iloc[:, 0:4].values\n",
        "train_y = training_dataset.iloc[:, 4].values\n",
        "\n",
        "# Encoding training dataset\n",
        "encoding_train_y = np_utils.to_categorical(train_y)\n",
        "\n",
        "# Import testing dataset\n",
        "test_dataset = pd.read_csv('iris_test.csv', names=COLUMN_NAMES, header=0)\n",
        "test_x = test_dataset.iloc[:, 0:4].values\n",
        "test_y = test_dataset.iloc[:, 4].values\n",
        "\n",
        "# Encoding training dataset\n",
        "encoding_test_y = np_utils.to_categorical(test_y)\n",
        "\n",
        "# Creating a model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compiling model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Training a model\n",
        "model.fit(train_x, encoding_train_y, epochs=300, batch_size=10)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(test_x, encoding_test_y)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
